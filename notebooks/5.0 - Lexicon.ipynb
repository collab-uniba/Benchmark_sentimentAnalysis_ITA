{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Sentix to Sentistrenght"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentix lexicon import and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Wordnet SynsetID</th>\n",
       "      <th>Pos Score</th>\n",
       "      <th>Neg Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abile</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intelligente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capace</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>incapace</td>\n",
       "      <td>a</td>\n",
       "      <td>2098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lemma POS  Wordnet SynsetID  Pos Score  Neg Score  Polarity  \\\n",
       "0         abile   a              1740      0.125       0.00       1.0   \n",
       "1  intelligente   a              1740      0.125       0.00       1.0   \n",
       "2       valente   a              1740      0.125       0.00       1.0   \n",
       "3        capace   a              1740      0.125       0.00       1.0   \n",
       "4      incapace   a              2098      0.000       0.75      -1.0   \n",
       "\n",
       "   Intensity  \n",
       "0      0.125  \n",
       "1      0.125  \n",
       "2      0.125  \n",
       "3      0.125  \n",
       "4      0.750  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentix = pd.read_csv('lexicon/sentix',sep='\\t',names=[\"Lemma\",\"POS\",\"Wordnet SynsetID\",\"Pos Score\",\"Neg Score\",\"Polarity\",\"Intensity\"])\n",
    "sentix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74606, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentix = sentix.dropna()\n",
    "#Actual size of the lexicon\n",
    "sentix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New polarity computation\n",
    "sentix['New_Pol'] = sentix['Polarity']*sentix['Intensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Wordnet SynsetID</th>\n",
       "      <th>Pos Score</th>\n",
       "      <th>Neg Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>New_Pol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abile</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intelligente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capace</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>incapace</td>\n",
       "      <td>a</td>\n",
       "      <td>2098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>-0.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lemma POS  Wordnet SynsetID  Pos Score  Neg Score  Polarity  \\\n",
       "0         abile   a              1740      0.125       0.00       1.0   \n",
       "1  intelligente   a              1740      0.125       0.00       1.0   \n",
       "2       valente   a              1740      0.125       0.00       1.0   \n",
       "3        capace   a              1740      0.125       0.00       1.0   \n",
       "4      incapace   a              2098      0.000       0.75      -1.0   \n",
       "\n",
       "   Intensity  New_Pol  \n",
       "0      0.125    0.125  \n",
       "1      0.125    0.125  \n",
       "2      0.125    0.125  \n",
       "3      0.125    0.125  \n",
       "4      0.750   -0.750  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polysemy management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Wordnet SynsetID</th>\n",
       "      <th>Pos Score</th>\n",
       "      <th>Neg Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>New_Pol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>buono</td>\n",
       "      <td>a</td>\n",
       "      <td>631391</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>buono</td>\n",
       "      <td>a</td>\n",
       "      <td>633410</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.748668</td>\n",
       "      <td>0.637377</td>\n",
       "      <td>0.477184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>buono</td>\n",
       "      <td>a</td>\n",
       "      <td>1123148</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>buono</td>\n",
       "      <td>a</td>\n",
       "      <td>1129977</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>buono</td>\n",
       "      <td>a</td>\n",
       "      <td>1372049</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>buono</td>\n",
       "      <td>a</td>\n",
       "      <td>1800349</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.748668</td>\n",
       "      <td>0.637377</td>\n",
       "      <td>0.477184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>buono</td>\n",
       "      <td>a</td>\n",
       "      <td>1983162</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22931</th>\n",
       "      <td>buono</td>\n",
       "      <td>n</td>\n",
       "      <td>4849241</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25724</th>\n",
       "      <td>buono</td>\n",
       "      <td>n</td>\n",
       "      <td>5142180</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32577</th>\n",
       "      <td>buono</td>\n",
       "      <td>n</td>\n",
       "      <td>6518068</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45674</th>\n",
       "      <td>buono</td>\n",
       "      <td>n</td>\n",
       "      <td>10138767</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45675</th>\n",
       "      <td>buono</td>\n",
       "      <td>n</td>\n",
       "      <td>10138767</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lemma POS  Wordnet SynsetID  Pos Score  Neg Score  Polarity  Intensity  \\\n",
       "759    buono   a            631391      0.625      0.000  1.000000   0.625000   \n",
       "770    buono   a            633410      0.625      0.125  0.748668   0.637377   \n",
       "1476   buono   a           1123148      0.750      0.000  1.000000   0.750000   \n",
       "1486   buono   a           1129977      1.000      0.000  1.000000   1.000000   \n",
       "1763   buono   a           1372049      0.625      0.000  1.000000   0.625000   \n",
       "2289   buono   a           1800349      0.625      0.125  0.748668   0.637377   \n",
       "2526   buono   a           1983162      1.000      0.000  1.000000   1.000000   \n",
       "22931  buono   n           4849241      0.875      0.000  1.000000   0.875000   \n",
       "25724  buono   n           5142180      0.625      0.000  1.000000   0.625000   \n",
       "32577  buono   n           6518068      0.125      0.000  1.000000   0.125000   \n",
       "45674  buono   n          10138767      0.375      0.000  1.000000   0.375000   \n",
       "45675  buono   n          10138767      0.375      0.000  1.000000   0.375000   \n",
       "\n",
       "        New_Pol  \n",
       "759    0.625000  \n",
       "770    0.477184  \n",
       "1476   0.750000  \n",
       "1486   1.000000  \n",
       "1763   0.625000  \n",
       "2289   0.477184  \n",
       "2526   1.000000  \n",
       "22931  0.875000  \n",
       "25724  0.625000  \n",
       "32577  0.125000  \n",
       "45674  0.375000  \n",
       "45675  0.375000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Terms like 'buono' have more than one record in the lexicon\n",
    "sentix[sentix['Lemma']=='buono']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'n', 'r', 'v'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get values for POS tagging used in the lexicon\n",
    "uniqueValues = (sentix['POS']).unique()\n",
    "uniqueValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change POS values used in the lexicon to POS values used in Spacy for further computation\n",
    "sentix['POS'] = sentix['POS'].replace(['a'],'adj')\n",
    "sentix['POS'] = sentix['POS'].replace(['n'],'noun')\n",
    "sentix['POS'] = sentix['POS'].replace(['r'],'adv')\n",
    "sentix['POS'] = sentix['POS'].replace(['v'],'verb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting New_Lemma\n",
    "sentix['New_Lemma'] = sentix['Lemma'] + '_' + sentix['POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Wordnet SynsetID</th>\n",
       "      <th>Pos Score</th>\n",
       "      <th>Neg Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>New_Pol</th>\n",
       "      <th>New_Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abile</td>\n",
       "      <td>adj</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>abile_adj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intelligente</td>\n",
       "      <td>adj</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>intelligente_adj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valente</td>\n",
       "      <td>adj</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>valente_adj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capace</td>\n",
       "      <td>adj</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>capace_adj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>incapace</td>\n",
       "      <td>adj</td>\n",
       "      <td>2098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>incapace_adj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lemma  POS  Wordnet SynsetID  Pos Score  Neg Score  Polarity  \\\n",
       "0         abile  adj              1740      0.125       0.00       1.0   \n",
       "1  intelligente  adj              1740      0.125       0.00       1.0   \n",
       "2       valente  adj              1740      0.125       0.00       1.0   \n",
       "3        capace  adj              1740      0.125       0.00       1.0   \n",
       "4      incapace  adj              2098      0.000       0.75      -1.0   \n",
       "\n",
       "   Intensity  New_Pol         New_Lemma  \n",
       "0      0.125    0.125         abile_adj  \n",
       "1      0.125    0.125  intelligente_adj  \n",
       "2      0.125    0.125       valente_adj  \n",
       "3      0.125    0.125        capace_adj  \n",
       "4      0.750   -0.750      incapace_adj  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep first entry for each Lemma_POS because, in WordNet, it has the highest absolute frequency\n",
    "sentix = sentix.drop_duplicates(subset=['New_Lemma'],keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Sentix New Polarity to SentiStrenght Polarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pd.options.mode.chained_assignment = None  \n",
    "\n",
    "#direct mapping of pos score, neg score and polarity through scaling\n",
    "def sentix_to_sentistrenght (df):\n",
    "    #New df deprived of useless columns for the purpose of converting to SentiStrenght format\n",
    "    sentix_ss = df[['Lemma','New_Lemma', 'New_Pol','Pos Score','Neg Score','Polarity','Intensity']]\n",
    "    #Separate dataframes for proper scaling\n",
    "    sentix_ss_pos = sentix_ss[sentix_ss['New_Pol']>0]\n",
    "    sentix_ss_neg = sentix_ss[sentix_ss['New_Pol']<0]\n",
    "    sentix_ss_neut = sentix_ss[sentix_ss['New_Pol']==0]\n",
    "\n",
    "    #Positive dataframe\n",
    "    #Min max scaling on polarity scores\n",
    "    scaler = MinMaxScaler(feature_range=(2,5))\n",
    "    sentix_ss_pos[['Polarity SS']] = scaler.fit_transform(sentix_ss_pos[['New_Pol']])\n",
    "    #Rounding of scaled scores\n",
    "    sentix_ss_pos[['Polarity SS']] = sentix_ss_pos[['Polarity SS']].round()\n",
    "\n",
    "    #Negative dataframe\n",
    "    #PolaritÃ  negativa\n",
    "    sentix_ss_neg['New_Pol'] = sentix_ss_neg['New_Pol'].abs()\n",
    "    #Min max scaling on polarity scores\n",
    "    scaler = MinMaxScaler(feature_range=(2,5))\n",
    "    sentix_ss_neg[['Polarity SS']] = scaler.fit_transform(sentix_ss_neg[['New_Pol']])\n",
    "    #Rounding of scaled scores\n",
    "    sentix_ss_neg[['Polarity SS']] = sentix_ss_neg[['Polarity SS']].round()\n",
    "    #Return the values to their original negativity\n",
    "    sentix_ss_neg['Polarity SS'] = -sentix_ss_neg['Polarity SS'].abs()\n",
    "    sentix_ss_neg['New_Pol'] = -sentix_ss_neg['New_Pol'].abs()\n",
    "\n",
    "    #Neutral dataframe\n",
    "    sentix_ss_neut['Polarity SS'] = (sentix_ss_neut['New_Pol'])\n",
    "\n",
    "    #Final dataframe mapped from Sentix to Sentistrenght\n",
    "    sentix_ss_total = pd.concat([sentix_ss_pos, sentix_ss_neg, sentix_ss_neut], axis=0)\n",
    "    sentix_ss_total['Polarity SS'] = sentix_ss_total['Polarity SS'].round()\n",
    "    sentix_ss_total = sentix_ss_total[['Lemma','New_Lemma','New_Pol','Polarity SS','Pos Score','Neg Score','Polarity','Intensity']]\n",
    "\n",
    "    return sentix_ss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentix_SS = sentix_to_sentistrenght(sentix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>New_Lemma</th>\n",
       "      <th>New_Pol</th>\n",
       "      <th>Polarity SS</th>\n",
       "      <th>Pos Score</th>\n",
       "      <th>Neg Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>buono</td>\n",
       "      <td>buono_adj</td>\n",
       "      <td>0.625</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22931</th>\n",
       "      <td>buono</td>\n",
       "      <td>buono_noun</td>\n",
       "      <td>0.875</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lemma   New_Lemma  New_Pol  Polarity SS  Pos Score  Neg Score  \\\n",
       "759    buono   buono_adj    0.625          4.0      0.625        0.0   \n",
       "22931  buono  buono_noun    0.875          5.0      0.875        0.0   \n",
       "\n",
       "       Polarity  Intensity  \n",
       "759         1.0      0.625  \n",
       "22931       1.0      0.875  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentix_SS[sentix_SS['Lemma']=='buono']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentix_SS.to_csv(\"sentix_ss.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03f8b8a1f797741164ec3397284a862f699c996acdec68272bf499e5af8d4843"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('sa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
